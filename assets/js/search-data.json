{
  
    
        "post0": {
            "title": "(4주차) 과제",
            "content": "1&#48264; . 설명변수가 1개($X$)이고, 반응변수가 1개($Y$)인데이터를 가지고 있다고 하자. $(n = 100)$ 그리고 다음의 두 모형(linear regression, cubic regression)을 적합시키려고 한다. . $$Y = beta_{0}+ beta_{1}X + varepsilon$$ . $$Y = beta_{0}+ beta_{1}X + beta_{2}X^2+ beta_{3}X 3+ varepsilon$$ . (a) . 실제 $X,Y$가 선형(linear)관계가 있다고 가정 하자. 모델 (1),(2)의 SSE(잔차제곱합)의 크기를 비교할 수 있는지 설명하여라. . Solution . (b) . 실제 $X, Y$ 가 비선형(non-linear)관계가 있다고 가정 하자. 대신 실제 모형에 대한 정보는 없다. 모델 (1),(2)의 $SSE$(잔차제곱합)의 크기를 비교할 수 있는지 설명하여라. . Solution . . 2&#48264; . ’Auto.csv’ 데이터를 이용하여 단순선형 회귀 모형을 적합한다. . (자료형 변환 후 결측치 제거) . library(tidyverse) data &lt;- read_csv(&quot;Auto(1).csv&quot;) data$horsepower &lt;- as.numeric(data$horsepower) glimpse(data) . Rows: 397 Columns: 9 -- Column specification Delimiter: &#34;,&#34; chr (2): horsepower, name dbl (7): mpg, cylinders, displacement, weight, acceleration, year, origin i Use `spec()` to retrieve the full column specification for this data. i Specify the column types or set `show_col_types = FALSE` to quiet this message. Warning message in eval(expr, envir, enclos): &#34;강제형변환에 의해 생성된 NA 입니다&#34; . Rows: 397 Columns: 9 $ mpg &lt;dbl&gt; 18, 15, 18, 16, 17, 15, 14, 14, 14, 15, 15, 14, 15, 14, 2~ $ cylinders &lt;dbl&gt; 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 4, 6, 6, 6, 4, ~ $ displacement &lt;dbl&gt; 307, 350, 318, 304, 302, 429, 454, 440, 455, 390, 383, 34~ $ horsepower &lt;dbl&gt; 130, 165, 150, 150, 140, 198, 220, 215, 225, 190, 170, 16~ $ weight &lt;dbl&gt; 3504, 3693, 3436, 3433, 3449, 4341, 4354, 4312, 4425, 385~ $ acceleration &lt;dbl&gt; 12.0, 11.5, 11.0, 12.0, 10.5, 10.0, 9.0, 8.5, 10.0, 8.5, ~ $ year &lt;dbl&gt; 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 7~ $ origin &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 3, ~ $ name &lt;chr&gt; &#34;chevrolet chevelle malibu&#34;, &#34;buick skylark 320&#34;, &#34;plymou~ . summary(data) . mpg cylinders displacement horsepower weight Min. : 9.00 Min. :3.000 Min. : 68.0 Min. : 46.0 Min. :1613 1st Qu.:17.50 1st Qu.:4.000 1st Qu.:104.0 1st Qu.: 75.0 1st Qu.:2223 Median :23.00 Median :4.000 Median :146.0 Median : 93.5 Median :2800 Mean :23.52 Mean :5.458 Mean :193.5 Mean :104.5 Mean :2970 3rd Qu.:29.00 3rd Qu.:8.000 3rd Qu.:262.0 3rd Qu.:126.0 3rd Qu.:3609 Max. :46.60 Max. :8.000 Max. :455.0 Max. :230.0 Max. :5140 NA&#39;s :5 acceleration year origin name Min. : 8.00 Min. :70.00 Min. :1.000 Length:397 1st Qu.:13.80 1st Qu.:73.00 1st Qu.:1.000 Class :character Median :15.50 Median :76.00 Median :1.000 Mode :character Mean :15.56 Mean :75.99 Mean :1.574 3rd Qu.:17.10 3rd Qu.:79.00 3rd Qu.:2.000 Max. :24.80 Max. :82.00 Max. :3.000 . data &lt;- na.omit(data) . (a) . 반응변수 mpg, 설명변수는 horsepower로 하는 단순선형회귀모형을 적합 시킨 후 summary() 함수의 결과 확인하고 다음의 물음에 답하여라. . fit1 &lt;- lm(mpg~horsepower,data) summary(fit1) . Call: lm(formula = mpg ~ horsepower, data = data) Residuals: Min 1Q Median 3Q Max -13.5710 -3.2592 -0.3435 2.7630 16.9240 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 39.935861 0.717499 55.66 &lt;2e-16 *** horsepower -0.157845 0.006446 -24.49 &lt;2e-16 *** Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 4.906 on 390 degrees of freedom Multiple R-squared: 0.6059, Adjusted R-squared: 0.6049 F-statistic: 599.7 on 1 and 390 DF, p-value: &lt; 2.2e-16 . (i) . 두 변수 사이에 관계가 있는가? . Solution . t 통계량에 근거한 p-value 값을 살펴본 결과 두 변수는 통계적으로 유의미한 선형관계에 있다 . (ii) . 두 변수 사이의 관계는 얼마나 강한가? . Solution . summary(fit1) . Call: lm(formula = mpg ~ horsepower, data = data) Residuals: Min 1Q Median 3Q Max -13.5710 -3.2592 -0.3435 2.7630 16.9240 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 39.935861 0.717499 55.66 &lt;2e-16 *** horsepower -0.157845 0.006446 -24.49 &lt;2e-16 *** Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 4.906 on 390 degrees of freedom Multiple R-squared: 0.6059, Adjusted R-squared: 0.6049 F-statistic: 599.7 on 1 and 390 DF, p-value: &lt; 2.2e-16 . horsepower 변수가 1씩 증가할 때 mpg 변수는 -0.1575 만큼 감소한다. . (iii) . 두 변수는 음의 관계가 있는가? 양의 관계가 있는가? . Solution . 추정된 $ beta_1$을 보았을 때 음의 관계이다. . (iv) . horsepower의 값이 98일 때, mpg의 예측값은 무엇인가 95% 신뢰구간은 무엇인가? . Solution . test &lt;- data.frame(horsepower=c(98)) predict(fit1,test,interval = &quot;confidence&quot;) . A matrix: 1 × 3 of type dbl fitlwrupr . 124.46708 | 23.97308 | 24.96108 | . (b) . 설명변수와 반응변수의 산점도를 그리고, 회귀직선을 추가하여라. (abline() 사용) . Solution . fit1$coefficients . . &lt;dl class=dl-inline&gt;(Intercept)39.9358610211705horsepower-0.157844733353654&lt;/dl&gt; options(repr.plot.res=150,repr.plot.width=10) plot(data$horsepower,data$mpg,xlab=&quot;horsepower&quot;,ylab=&quot;mpg&quot;,main = &quot;plot with abline&quot;) abline(a = fit1$coefficients[1],b=fit1$coefficients[2],col=&quot;red&quot;,lwd=2) . . . 3&#48264; . 이 문제는 다중공선성(collinearity)에 관련한 것이다. . (a) . R . set.seed(1) x1 = runif(100) x2 = 0.5*x1 + rnorm(100)/10 y = 2 + 2*x1+0.3*x2 + rnorm(100) . 마지막 줄이 두개의 설명변수를 이용한 중회귀모형이다. 회귀모형을 쓰시오. ($ beta$ 등을 이용하여) . Solution . set.seed(1) x1 = runif(100) x2 = 0.5*x1 + rnorm(100)/10 y = 2 + 2*x1+0.3*x2 + rnorm(100) . . $$y= beta_1 x_1 + beta_2 x_2 + varepsilon, quad varepsilon sim N(0, sigma^2)$$ . (b) . 두 설명변수 $x_1$과 $x_2$ 사이에 상관관계(correlation)이 있는가? 산점도를 그려서 확인하여라 . Solution . plot(x1,x2,main = &quot;x1, x2 correlation&quot;) abline(a=-0.1,b=1,col=&quot;red&quot;) . 산점도를 그려본 결과 $x1,x2$의 분포가 직선 형태의 가까운 형태이다. . (c) . 생성된 데이터를 이용하여 (a) 모형의 회귀계수를 추정하여라. 실제 회귀계수와 추정된 회귀계수와 비교하여라. $H_0 : beta_1 = 0$을 기각할 수 있는가? $H_1 : beta_2 = 0$을 기각할 수 있는가? . Solution . fit2 &lt;- lm(y~x1+x2) summary(fit2) . . Call: lm(formula = y ~ x1 + x2) Residuals: Min 1Q Median 3Q Max -2.8311 -0.7273 -0.0537 0.6338 2.3359 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 2.1305 0.2319 9.188 7.61e-15 *** x1 1.4396 0.7212 1.996 0.0487 * x2 1.0097 1.1337 0.891 0.3754 Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 1.056 on 97 degrees of freedom Multiple R-squared: 0.2088, Adjusted R-squared: 0.1925 F-statistic: 12.8 on 2 and 97 DF, p-value: 1.164e-05 . t 통계량에 근거한 p-value 값을 보았을 때 $H_0 : beta_1 = 0$ 이라는 기각가능하나, $H_0 : beta_2 = 0$ 기각하지 못한다 . (d) . 이번에는 $x_1$만을 이용한 단순선형회귀 모형을 적합하여라. 결과를 분석하여라. $H_0 : beta_1 = 0$을 기각할 수 있는가 . Solution . fit3 &lt;- lm(y~x1) summary(fit3) . . Call: lm(formula = y ~ x1) Residuals: Min 1Q Median 3Q Max -2.89495 -0.66874 -0.07785 0.59221 2.45560 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 2.1124 0.2307 9.155 8.27e-15 *** x1 1.9759 0.3963 4.986 2.66e-06 *** Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 1.055 on 98 degrees of freedom Multiple R-squared: 0.2024, Adjusted R-squared: 0.1942 F-statistic: 24.86 on 1 and 98 DF, p-value: 2.661e-06 . 기각 가능하다. . (e) . 이번에는 $x_2$만을 이용한 단순선형회귀 모형을 적합하여라. 결과를 분석하여라. $H_0 : beta_2 = 0$을 기각할 수 있는가? . Solution . fit4 &lt;- lm(y~x2) summary(fit4) . . Call: lm(formula = y ~ x2) Residuals: Min 1Q Median 3Q Max -2.62687 -0.75156 -0.03598 0.72383 2.44890 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 2.3899 0.1949 12.26 &lt; 2e-16 *** x2 2.8996 0.6330 4.58 1.37e-05 *** Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 1.072 on 98 degrees of freedom Multiple R-squared: 0.1763, Adjusted R-squared: 0.1679 F-statistic: 20.98 on 1 and 98 DF, p-value: 1.366e-05 . 기각 가능하다 . (f) . (c)-(e)의 결과가 서로 모순되는가? 설명하여라. . Solution . 결론 : 모순이 아니다 . 현재 $x_1,x_2$를 독립변수로 $y$를 반응변수로 하여 적합한 모델은 $ beta_1 neq0$, $ beta_2=0$이다. . 그러나 $x_1,x_2$ 각각의 경우를 $y$변수에 적합한 결과 $ beta_i neq 0, quad i= {1,2 }$를 보였다. . 현재 $x_2= 0.5 times x_1 + varepsilon$의 형태이다. . 즉 $x_2$와 $x_1$을 이미 선형관계를 전제했기 때문에 두 변수를 이용하여 $y$변수에 적합시킬 경우 다중공선성의 문제로 인하여 위와 같은 현상이 발생한다. 따라서 이는 모순이 아닌 합당한 결과이다. $x_1,x_2$는 선형의 관계이므로 주성분 분석을 이용하여 하나의 변수로 통합키킬 수 있다. . (g) . 새로운 데이터가 관측되었다고 하자.(이 데이터는 잘못 측정된 것이다.) . R . x1 &lt;- c(x1,0.1) x2 &lt;- c(x2,0.8) . 추가된 데이터를 이용하여 (c)-(e)를 다시 적합하여라. 결과가 어떻게 달라졌는가? 각 모형에서 새로 운 데이터는 이상점인가?(잔차가 기존에 있는 데이터에 비해 많이 큰가?) 아니면 영향점인가?(추가된 데이터로 인해 회귀계수의 값이 많이 바뀌었는가?) 설명하여라. . Solution . x1 &lt;- c(x1,0.1) x2 &lt;- c(x2,0.8) y &lt;- c(y,6) . . f1 &lt;- lm(y~x1+x2) f2 &lt;- lm(y~x1) f3 &lt;- lm(y~x2) . summary(f1);summary(f2);summary(f3) . Call: lm(formula = y ~ x1 + x2) Residuals: Min 1Q Median 3Q Max -2.73348 -0.69318 -0.05263 0.66385 2.30619 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 2.2267 0.2314 9.624 7.91e-16 *** x1 0.5394 0.5922 0.911 0.36458 x2 2.5146 0.8977 2.801 0.00614 ** Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 1.075 on 98 degrees of freedom Multiple R-squared: 0.2188, Adjusted R-squared: 0.2029 F-statistic: 13.72 on 2 and 98 DF, p-value: 5.564e-06 . Call: lm(formula = y ~ x1) Residuals: Min 1Q Median 3Q Max -2.8897 -0.6556 -0.0909 0.5682 3.5665 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 2.2569 0.2390 9.445 1.78e-15 *** x1 1.7657 0.4124 4.282 4.29e-05 *** Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 1.111 on 99 degrees of freedom Multiple R-squared: 0.1562, Adjusted R-squared: 0.1477 F-statistic: 18.33 on 1 and 99 DF, p-value: 4.295e-05 . Call: lm(formula = y ~ x2) Residuals: Min 1Q Median 3Q Max -2.64729 -0.71021 -0.06899 0.72699 2.38074 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 2.3451 0.1912 12.264 &lt; 2e-16 *** x2 3.1190 0.6040 5.164 1.25e-06 *** Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 1.074 on 99 degrees of freedom Multiple R-squared: 0.2122, Adjusted R-squared: 0.2042 F-statistic: 26.66 on 1 and 99 DF, p-value: 1.253e-06 . 새로운 데이터를 추가 후 결과를 살펴본 결과 개별 변수를 적합시킨 경우는 이전과 동일하게 $ beta_i neq 0$이었으나 두 변수를 모두 적합시킨 회귀모형은 $ beta_2 neq0, beta_1=0$의 가설을 채택하였다. 또한, $ beta_i$의 값이 많이 바뀐 경우는 두 변수를 모두 적합시킨 회귀모형을 제외하고 큰 변화가 없었다. . options(repr.plot.res=150,repr.plot.hight=4) par(mfrow=c(1,2)) boxplot(fit2$residuals,main=&quot;대이터 추가 전 잔차 (y=x1+x2)&quot;,ylim=c(-3,3));boxplot(f1$residuals,main=&quot;대이터 추가 후 잔차 (y=x1+x2)&quot;,ylim=c(-3,3)) . . boxplot을 통해 데이터 추가 전,후 $y=x1+x2$에 대한 잔차를 살펴보았다. 현재 $x_1$에는 0.1,$x_2$에는 0.8이 추가되었는데 $y=x1+x2$에 대한 잔차의 경우 크게 새로 추가된 데이터로 인하여 큰 변화가 없어보인다. . options(repr.plot.res=150,repr.plot.hight=4) par(mfrow=c(1,2)) boxplot(fit3$residuals,main=&quot;대이터 추가 전 잔차 (y=x1)&quot;,ylim=c(-3,3));boxplot(f2$residuals,main=&quot;대이터 추가 후 잔차 (y=x1)&quot;,ylim=c(-3,3)) . . $y=x_1$에 대한 잔차 분포를 살펴본 결과 데이터 추가 후 잔차의 이상치로 보이는 점의 개수가 늘었다. . options(repr.plot.res=150,repr.plot.hight=4) par(mfrow=c(1,2)) boxplot(fit4$residuals,main=&quot;대이터 추가 전 잔차 (y=x2)&quot;,ylim=c(-3,3));boxplot(f3$residuals,main=&quot;대이터 추가 후 잔차 (y=x2)&quot;,ylim=c(-3,3)) . . $y=x_2$에 대한 잔차 분포를 살펴본 결과 데이터 추가 후 잔차의 크기 변화가 거의 없다. . 결론 . 1 새로 추가된 데이터들은 $y=x_1+x_2$에서 회귀계수의 변화가 크므로 영향점이라고 판단되나 잔차의 변화가 미비해 이상점이라고 판단하기 어렵다. . 2 $y=x_1$에서는 데이터 추가 후 이상치로 판단되는 잔차의 수가 늘었다. 따라서 $y=x_1$ 모델에서 추가된 데이터들은 이상점이라고 판단된다. . 3 $y=x_2$ 에서는 데이터 추가 후 이상치로 판단되는 잔차가 관측되지 않았으며 회귀계수의 큰 변화도 보이지 않았다. 따라서 $y=x2$에서 추가된 데이터들은 이상점도 영향점도 아니다. . . Exercises for Logistic Regression . 1&#48264; . 두개의 설명변수 (X1 = 공부시간, X2 = 학부평점)를 이용하여 A학점을 받을 확률을 예측하기 위해 로지스틱 회귀모형을 적합하였다. 추정된 회귀계수는 $ beta_0 = −6, , beta_1 = 0.05, , beta_2 = 1$이다. . (a) . 40시간 공부하고, 평점이 3.5인 학생이 A를 받았을 확률을 예측하여라. . Solution . (b) . 평점이 3.5인 학생은 얼마나 공부를 해야 A를 받을 확률이 50%를 넘을 것인가? . Solution . 2&#48264; . 다음은 odds에 관한 문제이다. . (a) . 신용카드결재 문제에서 결재를 하지 못하는 경우(default)에 대한 odds가 0.37인 사람들이 실제로 defalut할 확률은 평균적으로 얼마인가? . Solution . (b) . 어떤 개인이 default할 확률이 16% 라고 하자. 그 사람이 default할 odds는 얼마인가? . Solution .",
            "url": "https://gangcheol.github.io/data-mining/2022/03/30/(4%EC%A3%BC%EC%B0%A8)-%EA%B3%BC%EC%A0%9C.html",
            "relUrl": "/2022/03/30/(4%EC%A3%BC%EC%B0%A8)-%EA%B3%BC%EC%A0%9C.html",
            "date": " • Mar 30, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "(1주차) 선형회귀분석",
            "content": "&#49440;&#54805;&#54924;&#44480;&#48516;&#49437; &#44592;&#52488; . 변수들간의 인과관계를 밝히고 모형을 적합하여 관심 있는 변수를 예측하거나 추론하기 위해 사용하는 분석기법 | . 선형회귀분석의 가정 오차의 등분산성 | 오차의 독립성 | 오차의 정규성 : Q-Q plot, Kolmogorov-Smirnov 검정, Shapiro-Wilk 검정을 확인하여 정규성을 확인한다. | . | . &#54924;&#44480;&#48516;&#49437; &#49884; &#44160;&#53664;&#49324;&#54637; . 0. 회귀모형이 통계적으로 유의한가 확인 . 1. 모형 내의 개별 회귀계수에 대한 검정 . 2. 모형에 설명력 $R^2$값을 통해 확인, 독립변수의 수가 많아지면 $adj-R^2$ 값을 확인 . 3. 잔차 plot을 통해 모형의 진단 . 4. 다중공선성의 확인 (10이상이면 다중공선성이 존재한다고 판단.) $ to$ car 패키지의 vif 함수 이용 . 5. 잔차분석 . R&#49892;&#49845; - &#45800;&#49692;&#49440;&#54805;&#54924;&#44480;&#48516;&#49437; . Cars93 데이터의 엔진크기(EngineSize)를 독립변수, 가격(Price)를 종속변수로 선정하여 단순 선형회귀분석을 실시한 후, 추정된 회귀모형에 대해 해석해보자. . library(MASS) library(lmtest) ## 더비왓슨 테스트를 위함 library(tidyverse) select &lt;- dplyr::select . . fit1 &lt;- lm(Price~EngineSize,data=Cars93) summary(fit1) . . Call: lm(formula = Price ~ EngineSize, data = Cars93) Residuals: Min 1Q Median 3Q Max -13.684 -4.627 -1.795 2.592 39.429 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 4.6692 2.2390 2.085 0.0398 * EngineSize 5.5629 0.7828 7.107 2.59e-10 *** Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 7.789 on 91 degrees of freedom Multiple R-squared: 0.3569, Adjusted R-squared: 0.3499 F-statistic: 50.51 on 1 and 91 DF, p-value: 2.588e-10 . plot(Cars93$EngineSize,Cars93$Price,lwd=2) abline(a=coefficients(fit1)[2],b=coefficients(fit1)[1],col=&quot;red&quot;,lwd=2) . . par(mfrow=c(1,2)) plot(fit1,1); plot(fit1,2) . . shapiro.test(resid(fit1)) . . Shapiro-Wilk normality test data: resid(fit1) W = 0.85365, p-value = 3.886e-08 . dwtest(fit1,alternative=&quot;two.sided&quot;) . . Durbin-Watson test data: fit1 DW = 1.1716, p-value = 2.236e-05 alternative hypothesis: true autocorrelation is not 0 . 1. 모형과 추정된 회귀계수는 모두 통계적으로 유의하다. . 2. 결정계수값과 수정된 결정계수 값이 각각 0.3569, 0.3499 로 산출되었다. . 3. F-통계량의 근거한 p-value값을 보아도 생성된 모델은 통계적으로 유의하다. . 4. 잔차 plot 을 그려본 결과 오차항의 정규성과 독립성 가정이 위배된 것 같다. . * 실제로 test 결과 위배되었다는 결론이 통계적으로 유의미했다. . 5. 따라서 모형의 식별 단계로 돌아가 새로운 모형을 적합할 필요가 있어보인다. . test &lt;- Cars93 %&gt;% select(EngineSize) %&gt;% sample_n(5) . . predict(fit1,test,interval=&quot;none&quot;) ##점추정 . . &lt;dl class=dl-inline&gt;123.0268912710567216.9076569678407324.1394793261868425.8083614088821523.5831852986217&lt;/dl&gt; predict(fit1,test,interval=&quot;confidence&quot;) # 회귀계수에 대한 신뢰구간을 고려한 구간 predict(fit1,test,interval=&quot;prediction&quot;) # 회귀계수에 대한 신뢰구간과 오차항을 고려한 구간 . . A matrix: 5 × 3 of type dbl fitlwrupr . 123.02689 | 21.14536 | 24.90842 | . 216.90766 | 15.14623 | 18.66909 | . 324.13948 | 22.07834 | 26.20061 | . 425.80836 | 23.42653 | 28.19019 | . 523.58319 | 21.61595 | 25.55043 | . A matrix: 5 × 3 of type dbl fitlwrupr . 123.02689 | 7.441846 | 38.61194 | . 216.90766 | 1.336654 | 32.47866 | . 324.13948 | 8.531732 | 39.74723 | . 425.80836 | 10.155035 | 41.46169 | . 523.58319 | 7.987560 | 39.17881 | . R&#49892;&#49845; - &#51473;&#54924;&#44480;&#48516;&#49437; . iris 데이터를 사용 | . R에 lm함수는 범주형 변수를 자동으로 더미변수로 변환해줌 | . fit2 &lt;- lm(Petal.Length~.,data=iris) summary(fit2) . . Call: lm(formula = Petal.Length ~ ., data = iris) Residuals: Min 1Q Median 3Q Max -0.78396 -0.15708 0.00193 0.14730 0.65418 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) -1.11099 0.26987 -4.117 6.45e-05 *** Sepal.Length 0.60801 0.05024 12.101 &lt; 2e-16 *** Sepal.Width -0.18052 0.08036 -2.246 0.0262 * Petal.Width 0.60222 0.12144 4.959 1.97e-06 *** Speciesversicolor 1.46337 0.17345 8.437 3.14e-14 *** Speciesvirginica 1.97422 0.24480 8.065 2.60e-13 *** Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 0.2627 on 144 degrees of freedom Multiple R-squared: 0.9786, Adjusted R-squared: 0.9778 F-statistic: 1317 on 5 and 144 DF, p-value: &lt; 2.2e-16 . dwtest(fit2,alternative=&quot;two.sided&quot;) . . Durbin-Watson test data: fit2 DW = 1.6772, p-value = 0.03042 alternative hypothesis: true autocorrelation is not 0 . shapiro.test(resid(fit2)) . . Shapiro-Wilk normality test data: resid(fit2) W = 0.99389, p-value = 0.78 . library(car) vif(fit2) . . A matrix: 4 × 3 of type dbl GVIFDfGVIF^(1/(2*Df)) . Sepal.Length 3.736705 | 1 | 1.933056 | . Sepal.Width 2.648127 | 1 | 1.627307 | . Petal.Width18.496973 | 1 | 4.300811 | . Species28.551416 | 2 | 2.311569 | . &#52572;&#51201;&#54924;&#44480;&#48169;&#51221;&#49885;&#51032; &#49440;&#53469; . &#44032;. &#45800;&#44228;&#51201; &#48320;&#49688;&#49440;&#53469;(Stepwise Variable Selection) . 1. 전진 선택법 (forward selection) : 절편만 있는 상수모형에서 시작하여 중요하다고 생각되는 설명변수부터 차례로 추가한다. . 2. 후진 제거법 (backward elimination) : 모든 독립변수를 포함한 모형에서 출발하여 종속변수에 가장 적은 영향을 주는 변수부터 하나씩 제거하면서 더 이상 제거할 변수가 없을 때의 모형을 선택한다. . 3. 단계적 방법 (stepwise method) : 전진선택법에 의해 변수를 추가하면서 새롭게 추가된 변수에 의해 기존 변수의 중요도가 약화되면 해당변수를 제거한다. . &#45208;. &#48268;&#51216;&#54868;&#46108; &#49440;&#53469;&#44592;&#51456; . 모형의 복잡도에 따라 벌점을 주는 방식으로 $AIC, BIC$ 값이 주로 사용된다. | . R&#49892;&#49845; : &#45796;&#51473;&#54924;&#44480;&#47784;&#54805; + &#48320;&#49688;&#49440;&#53469;&#48277; . fit3 &lt;- step(lm(Price~ EngineSize +Horsepower +RPM + Width + Length + Weight,Cars93),direction = &quot;both&quot;) summary(fit3) . . Start: AIC=322.11 Price ~ EngineSize + Horsepower + RPM + Width + Length + Weight Df Sum of Sq RSS AIC - EngineSize 1 1.69 2556.1 320.17 - RPM 1 19.71 2574.1 320.82 &lt;none&gt; 2554.4 322.11 - Length 1 119.55 2674.0 324.36 - Weight 1 209.73 2764.2 327.45 - Width 1 585.01 3139.4 339.29 - Horsepower 1 720.84 3275.3 343.22 Step: AIC=320.17 Price ~ Horsepower + RPM + Width + Length + Weight Df Sum of Sq RSS AIC - RPM 1 49.36 2605.5 319.95 &lt;none&gt; 2556.1 320.17 + EngineSize 1 1.69 2554.4 322.11 - Length 1 140.92 2697.0 323.16 - Weight 1 208.09 2764.2 325.45 - Width 1 593.56 3149.7 337.59 - Horsepower 1 1476.65 4032.8 360.57 Step: AIC=319.95 Price ~ Horsepower + Width + Length + Weight Df Sum of Sq RSS AIC &lt;none&gt; 2605.5 319.95 + RPM 1 49.36 2556.1 320.17 + EngineSize 1 31.34 2574.1 320.82 - Length 1 132.02 2737.5 322.54 - Weight 1 279.31 2884.8 327.42 - Width 1 562.10 3167.6 336.12 - Horsepower 1 1898.74 4504.2 368.86 . Call: lm(formula = Price ~ Horsepower + Width + Length + Weight, data = Cars93) Residuals: Min 1Q Median 3Q Max -14.956 -2.578 -0.182 2.114 28.448 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 53.005861 16.532269 3.206 0.00188 ** Horsepower 0.129653 0.016190 8.008 4.46e-12 *** Width -1.480623 0.339813 -4.357 3.56e-05 *** Length 0.152968 0.072440 2.112 0.03755 * Weight 0.007339 0.002389 3.071 0.00283 ** Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 5.441 on 88 degrees of freedom Multiple R-squared: 0.6965, Adjusted R-squared: 0.6827 F-statistic: 50.48 on 4 and 88 DF, p-value: &lt; 2.2e-16 .",
            "url": "https://gangcheol.github.io/data-mining/r/jupyter/2022/03/03/(1%EC%A3%BC%EC%B0%A8)-%EC%84%A0%ED%98%95%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D.html",
            "relUrl": "/r/jupyter/2022/03/03/(1%EC%A3%BC%EC%B0%A8)-%EC%84%A0%ED%98%95%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D.html",
            "date": " • Mar 3, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://gangcheol.github.io/data-mining/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Github . github . Soundcloud . C.I.C . NLP . NLP . Data Mining . Data Mining . Bigdata Analysis . Bigdata Analysis .",
          "url": "https://gangcheol.github.io/data-mining/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://gangcheol.github.io/data-mining/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}